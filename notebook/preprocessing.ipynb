{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import numpy as np\n",
    "from scipy.optimize import linprog\n",
    "import os\n",
    "from PIL import ImageDraw, Image\n",
    "import json\n",
    "import pytesseract\n",
    "from pytesseract import Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_back(r, w, h): return [int(r[0]*w),\n",
    "                                 int(r[1]*h), int(r[2]*w), int(r[3]*h)]\n",
    "\n",
    "\n",
    "def center(r): return ((r[0] + r[2]) / 2, (r[1] + r[3]) / 2)\n",
    "\n",
    "\n",
    "def isIn(c, r):\n",
    "    if c[0] < r[0] or c[0] > r[2]:\n",
    "        return False\n",
    "    elif c[1] < r[1] or c[1] > r[3]:\n",
    "        return False\n",
    "    else:\n",
    "        return True\n",
    "\n",
    "\n",
    "def match_pred_w_gt(bbox_preds: torch.Tensor, bbox_gts: torch.Tensor, links_pair: list):\n",
    "    bbox_iou = torchvision.ops.box_iou(boxes1=bbox_preds, boxes2=bbox_gts)\n",
    "    bbox_iou = bbox_iou.numpy()\n",
    "\n",
    "    A_ub = np.zeros(shape=(\n",
    "        bbox_iou.shape[0] + bbox_iou.shape[1], bbox_iou.shape[0] * bbox_iou.shape[1]))\n",
    "    for r in range(bbox_iou.shape[0]):\n",
    "        st = r * bbox_iou.shape[1]\n",
    "        A_ub[r, st:st + bbox_iou.shape[1]] = 1\n",
    "    for j in range(bbox_iou.shape[1]):\n",
    "        r = j + bbox_iou.shape[0]\n",
    "        A_ub[r, j::bbox_iou.shape[1]] = 1\n",
    "    b_ub = np.ones(shape=A_ub.shape[0])\n",
    "\n",
    "    assignaments_score = linprog(\n",
    "        c=-bbox_iou.reshape(-1), A_ub=A_ub, b_ub=b_ub, bounds=(0, 1), method=\"highs-ds\")\n",
    "    #assignaments_score = linprog(c=-bbox_iou.reshape(-1), bounds=(0, 1), method=\"highs-ds\")\n",
    "    # print(assignaments_score)\n",
    "    if not assignaments_score.success:\n",
    "        print(\"Optimization FAILED\")\n",
    "    assignaments_score = assignaments_score.x.reshape(bbox_iou.shape)\n",
    "    assignaments_ids = assignaments_score.argmax(axis=1)\n",
    "\n",
    "    # matched\n",
    "    opt_assignaments = {}\n",
    "    for idx in range(assignaments_score.shape[0]):\n",
    "        if (bbox_iou[idx, assignaments_ids[idx]] > 0.5) and (assignaments_score[idx, assignaments_ids[idx]] > 0.9):\n",
    "            opt_assignaments[idx] = assignaments_ids[idx]\n",
    "    # unmatched predictions\n",
    "    false_positive = [idx for idx in range(\n",
    "        bbox_preds.shape[0]) if idx not in opt_assignaments]\n",
    "    # unmatched gts\n",
    "    false_negative = [idx for idx in range(\n",
    "        bbox_gts.shape[0]) if idx not in opt_assignaments.values()]\n",
    "\n",
    "    gt2pred = {v: k for k, v in opt_assignaments.items()}\n",
    "    link_false_neg = []\n",
    "    for link in links_pair:\n",
    "        if link[0] in false_negative or link[1] in false_negative:\n",
    "            link_false_neg.append(link)\n",
    "\n",
    "    if len(links_pair) != 0:\n",
    "        rate = len(link_false_neg) / len(links_pair)\n",
    "    else:\n",
    "        rate = 0\n",
    "    return {\"pred2gt\": opt_assignaments, \"gt2pred\": gt2pred, \"false_positive\": false_positive, \"false_negative\": false_negative, \"n_link_fn\": int(len(link_false_neg) / 2), \"link_loss\": rate, \"entity_loss\": len(false_positive) / (len(false_positive) + len(opt_assignaments.keys()))}\n",
    "\n",
    "\n",
    "def get_objects(path, mode):\n",
    "    # TODO given a document, apply OCR or Yolo to detect either words or entities.\n",
    "    return\n",
    "\n",
    "\n",
    "def load_predictions(path_preds, path_gts, path_images, debug=False):\n",
    "    # TODO read txt file and pass bounding box to the other function.\n",
    "\n",
    "    boxs_preds = []\n",
    "    boxs_gts = []\n",
    "    links_gts = []\n",
    "    labels_gts = []\n",
    "    texts_ocr = []\n",
    "    all_paths = []\n",
    "\n",
    "    for img in os.listdir(path_images):\n",
    "        all_paths.append(os.path.join(path_images, img))\n",
    "        w, h = Image.open(os.path.join(path_images, img)).size\n",
    "        texts = pytesseract.image_to_data(Image.open(\n",
    "            os.path.join(path_images, img)), output_type=Output.DICT)\n",
    "        tp = []\n",
    "        n_elements = len(texts['level'])\n",
    "        for t in range(n_elements):\n",
    "            if int(texts['conf'][t]) > 50 and texts['text'][t] != ' ':\n",
    "                b = [texts['left'][t], texts['top'][t], texts['left'][t] +\n",
    "                     texts['width'][t], texts['top'][t] + texts['height'][t]]\n",
    "                tp.append([b, texts['text'][t]])\n",
    "        texts_ocr.append(tp)\n",
    "        preds_name = img.split(\".\")[0] + '.txt'\n",
    "        with open(os.path.join(path_preds, preds_name), 'r') as preds:\n",
    "            lines = preds.readlines()\n",
    "            boxs = list()\n",
    "            for line in lines:\n",
    "                scaled = scale_back([float(c)\n",
    "                                    for c in line[:-1].split(\" \")[1:]], w, h)\n",
    "                sw, sh = scaled[2] / 2, scaled[3] / 2\n",
    "                boxs.append([scaled[0] - sw, scaled[1] - sh,\n",
    "                            scaled[0] + sw, scaled[1] + sh])\n",
    "            boxs_preds.append(boxs)\n",
    "\n",
    "        gts_name = img.split(\".\")[0] + '.json'\n",
    "        with open(os.path.join(path_gts, gts_name), 'r') as f:\n",
    "            form = json.load(f)['form']\n",
    "            boxs = list()\n",
    "            pair_labels = []\n",
    "            ids = []\n",
    "            labels = []\n",
    "            for elem in form:\n",
    "                boxs.append([float(e) for e in elem['box']])\n",
    "                ids.append(elem['id'])\n",
    "                labels.append(elem['label'])\n",
    "                [pair_labels.append(pair) for pair in elem['linking']]\n",
    "\n",
    "            for p, pair in enumerate(pair_labels):\n",
    "                pair_labels[p] = [ids.index(pair[0]), ids.index(pair[1])]\n",
    "\n",
    "            boxs_gts.append(boxs)\n",
    "            links_gts.append(pair_labels)\n",
    "            labels_gts.append(labels)\n",
    "\n",
    "    all_links = []\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    all_texts = []\n",
    "    dropped_links = 0\n",
    "    dropped_entity = 0\n",
    "\n",
    "    for p in range(len(boxs_preds)):\n",
    "        d = match_pred_w_gt(torch.tensor(\n",
    "            boxs_preds[p]), torch.tensor(boxs_gts[p]), links_gts[p])\n",
    "        dropped_links += d['link_loss']\n",
    "        dropped_entity += d['entity_loss']\n",
    "        links = list()\n",
    "\n",
    "        for link in links_gts[p]:\n",
    "            if link[0] in d['false_negative'] or link[1] in d['false_negative']:\n",
    "                continue\n",
    "            else:\n",
    "                links.append([d['gt2pred'][link[0]], d['gt2pred'][link[1]]])\n",
    "        all_links.append(links)\n",
    "\n",
    "        preds = []\n",
    "        labels = []\n",
    "        texts = []\n",
    "        for b, box in enumerate(boxs_preds[p]):\n",
    "            if b in d['false_positive']:\n",
    "                preds.append(box)\n",
    "                labels.append('other')\n",
    "            else:\n",
    "                gt_id = d['pred2gt'][b]\n",
    "                preds.append(box)\n",
    "                labels.append(labels_gts[p][gt_id])\n",
    "\n",
    "            text = ''\n",
    "            for tocr in texts_ocr[p]:\n",
    "                if isIn(center(tocr[0]), box):\n",
    "                    text += tocr[1] + ' '\n",
    "\n",
    "            texts.append(text)\n",
    "\n",
    "        all_preds.append(preds)\n",
    "        all_labels.append(labels)\n",
    "        all_texts.append(texts)\n",
    "    print(dropped_links / len(boxs_preds), dropped_entity / len(boxs_preds))\n",
    "\n",
    "    if debug:\n",
    "        # random.seed(35)\n",
    "        # rand_idx = random.randint(0, len(os.listdir(path_images)))\n",
    "        print(all_texts[0])\n",
    "        rand_idx = 0\n",
    "        img = Image.open(os.path.join(path_images, os.listdir(\n",
    "            path_images)[rand_idx])).convert('RGB')\n",
    "        draw = ImageDraw.Draw(img)\n",
    "\n",
    "        rand_boxs_preds = boxs_preds[rand_idx]\n",
    "        rand_boxs_gts = boxs_gts[rand_idx]\n",
    "\n",
    "        for box in rand_boxs_gts:\n",
    "            draw.rectangle(box, outline='blue', width=3)\n",
    "        for box in rand_boxs_preds:\n",
    "            draw.rectangle(box, outline='red', width=3)\n",
    "\n",
    "        d = match_pred_w_gt(torch.tensor(rand_boxs_preds),\n",
    "                            torch.tensor(rand_boxs_gts), links_gts[rand_idx])\n",
    "        print(d)\n",
    "        for idx in d['pred2gt'].keys():\n",
    "            draw.rectangle(rand_boxs_preds[idx], outline='green', width=3)\n",
    "\n",
    "        link_true_pos = list()\n",
    "        link_false_neg = list()\n",
    "        for link in links_gts[rand_idx]:\n",
    "            if link[0] in d['false_negative'] or link[1] in d['false_negative']:\n",
    "                link_false_neg.append(link)\n",
    "                start = rand_boxs_gts[link[0]]\n",
    "                end = rand_boxs_gts[link[1]]\n",
    "                draw.line((center(start), center(end)), fill='red', width=3)\n",
    "            else:\n",
    "                link_true_pos.append(link)\n",
    "                start = rand_boxs_preds[d['gt2pred'][link[0]]]\n",
    "                end = rand_boxs_preds[d['gt2pred'][link[1]]]\n",
    "                draw.line((center(start), center(end)), fill='green', width=3)\n",
    "\n",
    "        precision = 0\n",
    "        recall = 0\n",
    "        for idx, gt in enumerate(boxs_gts):\n",
    "            d = match_pred_w_gt(torch.tensor(\n",
    "                boxs_preds[idx]), torch.tensor(gt), links_gts[rand_idx])\n",
    "            bbox_true_positive = len(d[\"pred2gt\"])\n",
    "            p = bbox_true_positive / \\\n",
    "                (bbox_true_positive + len(d[\"false_positive\"]))\n",
    "            r = bbox_true_positive / \\\n",
    "                (bbox_true_positive + len(d[\"false_negative\"]))\n",
    "            # f1 += (2 * p * r) / (p + r)\n",
    "            precision += p\n",
    "            recall += r\n",
    "\n",
    "        precision = precision / len(boxs_gts)\n",
    "        recall = recall / len(boxs_gts)\n",
    "        f1 = (2 * precision * recall) / (precision + recall)\n",
    "        # print(f1, precision, recall)\n",
    "\n",
    "        img.save('prova.png')\n",
    "\n",
    "    return all_paths, all_preds, all_links, all_labels, all_texts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA = \"dataj/datasets/\"\n",
    "FUNSD_TEST = \n",
    "path_preds = DATA / 'FUNSD' / 'test_bbox'\n",
    "path_images = FUNSD_TEST / 'images'\n",
    "path_gts = FUNSD_TEST / 'adjusted_annotations'\n",
    "load_predictions(path_preds, path_gts, path_images, debug=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
